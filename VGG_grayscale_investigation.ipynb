{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first just see what happens when we run a single gray scale image through VGG\n",
    "# Hypotheses\n",
    "#   - It will through an error/break in some overt way\n",
    "#   - It will not throw an error, and just fucking suck\n",
    "#\n",
    "# Before we even do this, so tha we can truly pinpoint both ofthese thoughts, let's pass an OBVIOUS \n",
    "# colored image of a vehicle through here, and then do the same image but in grayscale. \n",
    "model = VGG16(weights='imagenet', include_top=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './color_cropped_images/cars/img0_car0.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2998e2d15e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Why tf are we doing this through a keras wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolor_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./color_cropped_images/cars/img0_car0.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcolor_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcolor_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size, interpolation)\u001b[0m\n\u001b[1;32m    347\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    348\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2543\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2544\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './color_cropped_images/cars/img0_car0.jpg'"
     ]
    }
   ],
   "source": [
    "# Why tf are we doing this through a keras wrapper \n",
    "color_img_path = './color_cropped_images/cars/img0_car0.jpg'\n",
    "color_img = image.load_img(color_img_path, target_size=(224, 224)) \n",
    "color_img = image.img_to_array(color_img)\n",
    "\n",
    "plt.imshow(color_img.astype(np.uint8))\n",
    "plt.show()\n",
    "\n",
    "# The default  here for the mode of the preprocess_input method is 'caffe'\n",
    "# which is actually what we want here because VGG16 was originally implemented in caffe\n",
    "color_img = np.expand_dims(color_img, axis=0)\n",
    "color_img = preprocess_input(color_img)\n",
    "\n",
    "results = model.predict(color_img)\n",
    "\n",
    "print('prediction: ', imagenet_classes.get(int(np.argmax(results))) )\n",
    "print('max_position: ', np.argmax(results))\n",
    "print('max: ', np.max(results))\n",
    "print('min', np.min(results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2df807b7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 57)\n"
     ]
    }
   ],
   "source": [
    "# So it thinks that that single image is a snowplow, which is wrong, but I think I can understand how\n",
    "# a neural network could see that as an analagous class\n",
    "# I am going to give it a whorl onthe same image but in grayscale and see if it even accepts it\n",
    "#\n",
    "gray_img_path = './cropped_split_dataset/test/cars/img1_car0.jpg'\n",
    "img = image.load_img(gray_img_path, target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(img.astype(np.uint8))\n",
    "plt.show()\n",
    "\n",
    "# So Here is an interesting revelation:\n",
    "#    The keras image loader automatically maps the grayscale image into a tensor with depth 3 \n",
    "#    but what does it actually do? It seems as through there is some operation by which it just replicates \n",
    "#    the image into each color channel in a way that the display of it through all three channels is just \n",
    "#    the grayscale image\n",
    "#\n",
    "# I am going to investigate to see if the file is interpreted as such when pulled in through something else\n",
    "import imageio as io\n",
    "io_img = io.imread(gray_img_path)\n",
    "print(io_img.shape)\n",
    "#\n",
    "# Results: The keras image preprocessor is the SHITITITTITITIITTII because it makes a 3D tensor \n",
    "# of your desired dimensions out of gray scale images.I wonder if this will disrupt how conv nets sees them\n",
    "#    but it can also take the \"grayscale\" argument and just take it in as a literal grayscale img \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  snowplow, snowplough\n",
      "max_position:  803\n",
      "max:  0.30434513\n",
      "min 1.5870116e-07\n"
     ]
    }
   ],
   "source": [
    "# Holy shit! When making a prediction with VGG on this grayscale image, it produced the\n",
    "# literal exact same certainties for the outputs of the minimum and maximum outputs on the class vector.\n",
    "# So I guess that preserving color information won't be overtly important in this case\n",
    "img = image.load_img(gray_img_path, target_size=(224, 224))\n",
    "img = image.img_to_array(img)\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)\n",
    "\n",
    "results = model.predict(color_img)\n",
    "\n",
    "print('prediction: ', imagenet_classes.get(int(np.argmax(results))) )\n",
    "print('max_position: ', np.argmax(results))\n",
    "print('max: ', np.max(results))\n",
    "print('min', np.min(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far, we have very inconclusive results for the amount of color-channel specific features\n",
    "# which were learned internally to VGG-16, but it seems as if the difference could be insignificant \n",
    "# enough when using the keras image loaders that we should just try to do some\n",
    "# transfer learning on it\n",
    "# First, let's create the image loaders for the training and validation data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
